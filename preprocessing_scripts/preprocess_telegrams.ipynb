{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pdb\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import unittest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Text\n",
    "\n",
    "To simplify the text anaylsis of the U.S. Civil Telegrams, the telegrams need to be preprocessed to remove volunteer generated metadata tags (e.g., `<deletion>`, `<insertion>`, and `<unclear>`), punctuation, as well as converting all characters to lower case.\n",
    "\n",
    "As these changes are applied, the changes are saved in a dictionary. The structure of this dictionary is:\n",
    "\n",
    "```\n",
    "telegram_changes = {\n",
    "    removed_tags: [], # array of tuples (e.g., (starting index, text of the selection))\n",
    "    removed_punctuation: [], # array of tuples (e.g., (starting index, ending index, text of the selection))\n",
    "    lower_cased_characters: [], # array of tuples (e.g., (starting index, text of the selection))\n",
    "    spaces_removed: []\n",
    "}\n",
    "```\n",
    "This script runs on one ledger at a time.\n",
    "\n",
    "\n",
    "## Inputs:\n",
    "- path to unprocessed text files\n",
    "- path to folder that will contain the outputs of this script\n",
    "\n",
    "## Outputs:\n",
    "This script generates the following file structure:\n",
    "\n",
    "- folder of each telegram\n",
    "    - txt file containing the unprocessed telegram\n",
    "    - txt file containing the processed telegram\n",
    "    - json file containing the dictionary of changes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "unprocessed_file_path = os.getenv('UNPROCESSED_TELEGRAMS_FOLDER')\n",
    "processed_file_path = os.getenv('PROCESSED_TELEGRAMS_FOLDER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_annotation_tags(telegrams_lines, removed_punctuation):\n",
    "    tag_pattern = \"(<deletion>|</deletion>|<insertion>|</insertion>|<unclear>|</unclear>)\"\n",
    "    removed_tags = []\n",
    "    telegrams_lines_without_tags = telegrams_lines\n",
    "    end_index = 0\n",
    "    while (end_index < len(telegrams_lines_without_tags)):\n",
    "        match = re.search(tag_pattern, telegrams_lines_without_tags)\n",
    "        if match:\n",
    "            start_index = int(match.start())\n",
    "            end_index = int(match.end())\n",
    "            telegrams_lines_without_tags = telegrams_lines_without_tags[0:start_index] + telegrams_lines_without_tags[end_index:]\n",
    "            tag = match.group(0)\n",
    "            removed_punctuation.append((match.start(), match.end(), tag))\n",
    "        else:\n",
    "            end_index = len(telegrams_lines_without_tags)\n",
    "    return (telegrams_lines_without_tags, removed_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# going through by charcter    \n",
    "def remove_punctuation(telegrams_lines, removed_punctuation):\n",
    "    telegram_lines_no_punctuation = \"\"\n",
    "    index = 0\n",
    "    for character in telegrams_lines:\n",
    "        if character not in string.punctuation:\n",
    "            telegram_lines_no_punctuation = '{0}{1}'.format(telegram_lines_no_punctuation, character)\n",
    "        else:\n",
    "            removed_punctuation.append((index, character))\n",
    "        index+=1\n",
    "    return (telegram_lines_no_punctuation, removed_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowercase_characters(telegrams_lines, removed_punctuation):\n",
    "    lowercase_telegram = \"\"\n",
    "    index = 0\n",
    "    for character in telegrams_lines:\n",
    "        if character in string.ascii_uppercase:\n",
    "            # lowercase the uppercase letter\n",
    "            lowercase_telegram = \"\".join([lowercase_telegram, character.lower()])\n",
    "            removed_punctuation.append((index, character))\n",
    "        else:\n",
    "            lowercase_telegram = \"\".join([lowercase_telegram, character])\n",
    "        index+=1\n",
    "    return (lowercase_telegram, removed_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_extra_spaces(telegrams_lines, removed_punctuation):\n",
    "    extra_space_pattern = \"(  ){1,}\"\n",
    "    remove_extra_space_telegram = telegrams_lines\n",
    "    end_index = 0\n",
    "    # this could be a separate method\n",
    "    while (end_index < len(remove_extra_space_telegram)):\n",
    "        match = re.search(extra_space_pattern, remove_extra_space_telegram)\n",
    "        if match:\n",
    "            start_index = int(match.start())\n",
    "            end_index = int(match.end())\n",
    "            remove_extra_space_telegram = remove_extra_space_telegram[0:start_index] + \" \" + remove_extra_space_telegram[end_index:]\n",
    "            tag = match.group(0)\n",
    "            removed_punctuation.append((match.start(), match.end(), tag))\n",
    "        else:\n",
    "            end_index = len(remove_extra_space_telegram)\n",
    "\n",
    "    return (remove_extra_space_telegram, removed_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dehydrate(telegrams_lines):\n",
    "    telegram_changes = {}\n",
    "    telegram_without_tags = remove_annotation_tags(telegrams_lines, [])\n",
    "    telegram_changes[\"removed_tags\"] = telegram_without_tags[1]\n",
    "\n",
    "    telegram_without_punctuation = remove_punctuation(telegram_without_tags[0], [])\n",
    "    telegram_changes[\"removed_punctuation\"] = telegram_without_punctuation[1]\n",
    "\n",
    "    telegram_lowercase_charaters = lowercase_characters(telegram_without_punctuation[0], [])\n",
    "    telegram_changes[\"lower_cased_characters\"] = telegram_lowercase_charaters[1]\n",
    "    \n",
    "    telegram_remove_extra_spaces = remove_extra_spaces(telegram_lowercase_charaters[0], [])\n",
    "    telegram_changes[\"spaces_removed\"] = telegram_remove_extra_spaces[1]\n",
    "    \n",
    "    normalized_telegram = telegram_remove_extra_spaces[0]\n",
    "    \n",
    "    return (normalized_telegram, telegram_changes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rehydrate(telegram_lowercase_charaters, telegram_changes):\n",
    "    rehydrated_telegrams = telegram_lowercase_charaters\n",
    "\n",
    "    if len(telegram_changes[\"spaces_removed\"]) > 0:\n",
    "        telegram_changes[\"spaces_removed\"].reverse()\n",
    "    \n",
    "    for change in telegram_changes[\"spaces_removed\"]:\n",
    "        index_of_change = change[0]\n",
    "        before_change = rehydrated_telegrams[0:index_of_change]\n",
    "        after_change = rehydrated_telegrams[index_of_change:]\n",
    "        # change[2][1:] because we left a space in, we don't want to overadd space\n",
    "        rehydrated_telegrams = \"\".join([before_change, change[2][1:], after_change])\n",
    "    \n",
    "    for change in telegram_changes[\"lower_cased_characters\"]:\n",
    "        index_of_change = change[0]\n",
    "        changed_character = change[1]\n",
    "        before_change = rehydrated_telegrams[0:index_of_change]\n",
    "        after_change = rehydrated_telegrams[index_of_change + 1:]\n",
    "        rehydrated_telegrams = \"\".join([before_change, changed_character.upper(), after_change])\n",
    "    \n",
    "    for change in telegram_changes[\"removed_punctuation\"]:\n",
    "        index_of_change = change[0]\n",
    "        before_change = rehydrated_telegrams[0:index_of_change]\n",
    "        after_change = rehydrated_telegrams[index_of_change:]\n",
    "        rehydrated_telegrams = \"\".join([before_change, change[1], after_change])\n",
    "\n",
    "    if len(telegram_changes[\"removed_tags\"]) > 0:\n",
    "        telegram_changes[\"removed_tags\"].reverse()\n",
    "    for change in telegram_changes[\"removed_tags\"]:\n",
    "        index_of_change = change[0]\n",
    "        before_change = rehydrated_telegrams[0:index_of_change]\n",
    "        after_change = rehydrated_telegrams[index_of_change:]\n",
    "        rehydrated_telegrams = \"\".join([before_change, change[2], after_change])\n",
    "    \n",
    "    return rehydrated_telegrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_telegram_folder(path):\n",
    "    try:\n",
    "        os.mkdir(path)\n",
    "    except FileExistsError:\n",
    "        print(\"ERROR: File already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_text_file(dehydrated_telegram, path, filename):\n",
    "    text_file_path = path + \"/\" + filename + \".txt\"\n",
    "    try:\n",
    "        with open(text_file_path, \"w\") as dehydrated_file:\n",
    "            dehydrated_file.write(dehydrated_telegram)\n",
    "    except IOError:\n",
    "        print(\"IOError: Error writing text file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_json_file(telegram_changes, path, filename):\n",
    "    json_file_path = path + \"/\" + filename + \".json\"\n",
    "    try:\n",
    "        with open(json_file_path, \"w\") as jsonfile:\n",
    "            try:\n",
    "                json.dump(telegram_changes, jsonfile, indent=4)\n",
    "            except TypeError:\n",
    "                print(\"TypeError writing JSON file.\")\n",
    "            except OverflowError:\n",
    "                print(\"TypeError writing JSON file.\")\n",
    "            except ValueError:\n",
    "                print(\"ValueError writing JSON file.\")\n",
    "    except IOError:\n",
    "        print(\"IOError: Error writing JSON file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (os.path.exists(unprocessed_file_path)):\n",
    "    for file in os.listdir(unprocessed_file_path):\n",
    "        if file.startswith(\".\"):\n",
    "            continue\n",
    "\n",
    "        pathname = os.path.join(unprocessed_file_path, file)\n",
    "        with open(pathname) as telegram:\n",
    "\n",
    "            print(\"--------------------------------------\")\n",
    "            print(\"File Name: \", file)\n",
    "\n",
    "            telegrams_lines = telegram.read()\n",
    "\n",
    "            # tuple of (normalized telegram text, telegram_changes)\n",
    "            dehydrated_telegram = dehydrate(telegrams_lines)\n",
    "            rehydrated_telegram = rehydrate(dehydrated_telegram[0], dehydrated_telegram[1])\n",
    "\n",
    "            print(\"\")\n",
    "            print(\"telegrams_lines\")\n",
    "            print(telegrams_lines)\n",
    "            print(\"\")\n",
    "            print(\"dehydrated_telegram\")\n",
    "            print(dehydrated_telegram[0])\n",
    "\n",
    "            filename = file[:-4]\n",
    "            processed_filename = \"preprocessed_\" +filename\n",
    "\n",
    "            # Create folder for telegram\n",
    "            processed_folder_name = processed_file_path + \"/\" + filename\n",
    "            create_telegram_folder(processed_folder_name)\n",
    "\n",
    "            # Write a json file that contains change tracking object\n",
    "            create_json_file(dehydrated_telegram[1], processed_folder_name, file[:-4])\n",
    "\n",
    "            # Write a text file with the processed telegram text\n",
    "            create_text_file(dehydrated_telegram[0], processed_folder_name, processed_filename)\n",
    "            create_text_file(telegrams_lines, processed_folder_name, filename)\n",
    "\n",
    "            print(\"--------------------------------------\")\n",
    "            print(\"\")\n",
    "            print(\"\")\n",
    "else:\n",
    "    print(\"path does not exist\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestStringMethods(unittest.TestCase):\n",
    "    def test_remove_annotation_tags(self):\n",
    "        example_string = \"<unclear>Ft Monroe</unclear> 4th 120 PM  Recd Jul 4 ' 62 \\n<insertion>Norfolk</insertion> <deletion>July</deletion> Fourth twelve thirty PM\"\n",
    "        string_to_match = \"Ft Monroe 4th 120 PM  Recd Jul 4 ' 62 \\nNorfolk July Fourth twelve thirty PM\"\n",
    "        removed_tags_example_string = remove_annotation_tags(example_string, [])\n",
    "        \n",
    "        self.assertEqual(removed_tags_example_string[0], string_to_match)\n",
    "        \n",
    "    def test_remove_punctuation(self):\n",
    "        example_string = \"Ft Monroe 4th 120 PM  Recd Jul 4 ' 62 \\nNorfolk July Fourth twelve thirty PM\"\n",
    "        string_to_match = \"Ft Monroe 4th 120 PM  Recd Jul 4  62 \\nNorfolk July Fourth twelve thirty PM\"\n",
    "        removed_punctuation_example_string = remove_punctuation(example_string, [])\n",
    "        \n",
    "        self.assertEqual(removed_punctuation_example_string[0], string_to_match)\n",
    "    \n",
    "    def test_lowercase_characters(self):\n",
    "        example_string = \"Ft Monroe 4th 120 PM  Recd Jul 4 ' 62 \\nNorfolk July Fourth twelve thirty PM\"\n",
    "        string_to_match = \"ft monroe 4th 120 pm  recd jul 4 ' 62 \\nnorfolk july fourth twelve thirty pm\"\n",
    "        lower_case_example_string = lowercase_characters(example_string, [])\n",
    "        \n",
    "        self.assertEqual(lower_case_example_string[0], string_to_match)  \n",
    "    \n",
    "    def test_dehydrated_telegram(self):\n",
    "        example_string = \"<unclear>Ft Monroe</unclear> 4th 120 PM  Recd Jul 4 ' 62 \\n<insertion>Norfolk</insertion> <deletion>July</deletion> Fourth twelve thirty PM\"\n",
    "        string_to_match = \"ft monroe 4th 120 pm  recd jul 4  62 \\nnorfolk july fourth twelve thirty pm\"\n",
    "        dehydrated_telegram_example = dehydrate(example_string)\n",
    "        self.assertEqual(dehydrated_telegram_example[0], string_to_match)\n",
    "    \n",
    "    def test_dehydrated_telegram(self):\n",
    "        example_string = \"<unclear>Ft Monroe</unclear> 4th 120 PM  Recd Jul 4 ' 62 \\n<insertion>Norfolk</insertion> <deletion>July</deletion> Fourth twelve thirty PM\"\n",
    "        dehydrated_telegram_example = dehydrate(example_string)\n",
    "        rehydtrated_telegram_example = rehydrate(dehydrated_telegram_example[0], dehydrated_telegram_example[1])\n",
    "        \n",
    "        self.assertEqual(rehydtrated_telegram_example, example_string)\n",
    "    \n",
    "    def test_remove_extra_spaces__two_spaces(self):\n",
    "        example_string = \"Ft Monroe 4th 120 PM  Recd Jul 4 ' 62 \\nNorfolk July Fourth twelve thirty PM\"\n",
    "        string_to_match = \"Ft Monroe 4th 120 PM Recd Jul 4 ' 62 \\nNorfolk July Fourth twelve thirty PM\"\n",
    "        example_string_removed_extra_spaces = remove_extra_spaces(example_string,[])\n",
    "        \n",
    "        self.assertEqual(example_string_removed_extra_spaces[0], string_to_match)\n",
    "    \n",
    "    def test_remove_extra_spaces__three_spaces(self):\n",
    "        example_string = \"Ft Monroe 4th 120 PM   Recd Jul 4 ' 62 \\nNorfolk July Fourth twelve thirty PM\"\n",
    "        string_to_match = \"Ft Monroe 4th 120 PM Recd Jul 4 ' 62 \\nNorfolk July Fourth twelve thirty PM\"\n",
    "        example_string_removed_extra_spaces = remove_extra_spaces(example_string,[])\n",
    "        \n",
    "        self.assertEqual(example_string_removed_extra_spaces[0], string_to_match)\n",
    "    \n",
    "    def test_remove_extra_spaces__multiple_spaces(self):\n",
    "        example_string = \"Ft Monroe 4th 120 PM   Recd Jul 4 ' 62 \\nNorfolk July  Fourth twelve thirty PM\"\n",
    "        string_to_match = \"Ft Monroe 4th 120 PM Recd Jul 4 ' 62 \\nNorfolk July Fourth twelve thirty PM\"\n",
    "        example_string_removed_extra_spaces = remove_extra_spaces(example_string,[])\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    unittest.main(argv=['first-arg-is-ignored'], exit=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
